callbacks:
  patience: -1
  tol: 0
data:
  networks: ["case30_ieee"]
  scenarios: [10]
  normalization: "baseMVAnorm"
  baseMVA: 100
  mask_type: "rnd"
  mask_value: 0.0
  mask_ratio: 0.5
  mask_dim: 6
  learn_mask: False
  val_ratio: 0.2
  test_ratio: 0.2
  workers: 0
model:
  attention_head: 8
  dropout: 0.1
  edge_dim: 2
  hidden_size: 64
  input_dim: 9
  num_layers: 8
  output_dim: 6
  pe_dim: 20
  type: GNN_TransformerConv
optimizer:
  beta1: 0.9
  beta2: 0.999
  learning_rate: 1.0e-05
  lr_decay: 0.7
  lr_patience: 10
seed: 200
training:
  batch_size: 2
  epochs: 1
  losses: ["MaskedMSE", "PBE", "MSE", "SCE"]
  loss_weights: [0.25, 0.25, 0.25, 0.25]
  accelerator: auto
  devices: auto
  strategy: auto
