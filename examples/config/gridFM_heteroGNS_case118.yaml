callbacks:
  patience: 100
  tol: 0
data:
  baseMVA: 100
  learn_mask: false
  mask_value: 0.0
  mask_type: opf_hetero
  normalization: heterobaseMVAnorm
  networks:
  - case118_ieee
  scenarios:
  - 300000
  test_ratio: 0.05
  val_ratio: 0.05
  workers: 16
model:
  attention_head: 8
  edge_dim: 2
  hidden_size: 48
  input_bus_dim: 12
  input_gen_dim: 6
  output_bus_dim: 5
  output_gen_dim: 1
  num_layers: 12
  dropout: 0.0
  type: GNN_PBE_HeteroTransformerConv
optimizer:
  beta1: 0.9
  beta2: 0.999
  learning_rate: 0.0001
  lr_decay: 0.7
  lr_patience: 5
seed: 0
training:
  batch_size: 32
  epochs: 200
  loss_weights:
  - 0.1
  - 0.9
  losses:
  - LayeredWeightedPhysicsLoss
  - MaskedOPFHeteroLoss
  base_weight: 0.6
  accelerator: auto
  devices: auto
  strategy: auto
verbose: false
